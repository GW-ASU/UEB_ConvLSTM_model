# coding: utf-8

from mxnet import nd
from mxnet.gluon import data as gdata
import h5py
import numpy as np
from model import try_gpu

def loaddata(datapath, i, len_each, num_parts, batch_size, look_back, shuffle=True):
    """
    Load the dataset.
    """
    print()
    print("Loading %d set of data..." %(i + 1))
    X1, Y = _get_data(datapath, i, look_back, len_each)
    seq_X1 = _get_x_seq(X1, look_back)
    seq_Y = _get_y_seq(Y)
    data_iter = gdata.DataLoader(gdata.ArrayDataset(seq_X1, seq_Y), batch_size, shuffle=shuffle)
    if i == 0:
        print('Please check following information about your dataset used in this model if any error occurs.')
        print('=============================================================================================')
        print('There is %d parts in total, and in each part:' %num_parts)
        print('Shapes of X and Y are', X1.shape, ',', Y.shape)
        print('Shapes of sequences generated by X and Y are', seq_X1.shape, ',', seq_Y.shape)
        print('Shapes of features and labels are', features1.shape, ',', labels.shape)
        print('The number of actual examples used in each part is', len(seq_Y))
        print('The number of actual examples used in all parts is', len(seq_Y) * num_parts, \
              ', it should be %d' %((len_each - look_back) * num_parts))
        print('=============================================================================================')
    return data_iter

def _get_data(datapath, i, look_back, len_each):
    """
    Get data from given datapath.
    """
    file = h5py.File(datapath, 'r')
    len_real = len_each - look_back
    Y = file['Y'][:, look_back + len_real * i: len_each + len_real * i]
    Y = nd.array(Y, ctx=try_gpu()).reshape(-1, 1)
    X1 = file['X1'][len_real * i: (len_each - 1) + len_real * i]
    X1 = nd.array(X1, ctx=try_gpu())
    return X1, Y

def _get_x_seq(dataset, look_back):
    """
    Generate the sequences of X tensor from given dataset.
    """
    assert isinstance(dataset, nd.ndarray.NDArray)
    seq = None
    len_real = len(dataset) - look_back + 1
    for i in range(int(len_real)):
        seq_i = dataset[int(i) : int(i + look_back)]
        seq_i = seq_i.expand_dims(axis=0)
        if seq is None:
            seq = seq_i
        else:
            seq = nd.concat(seq, seq_i, dim = 0)
    return seq

def _get_y_seq(dataset):
    """
    Generate the sequences of Y tensor from given dataset.
    """
    assert isinstance(dataset, nd.ndarray.NDArray)
    return dataset
